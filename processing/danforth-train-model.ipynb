{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import Generator\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, DeviceStatsMonitor, EarlyStopping, RichProgressBar\n",
    "from lightning.pytorch.profilers import PyTorchProfiler\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "from data import DanforthDataset\n",
    "from models import TrainingModel, UNet\n",
    "\n",
    "from skimage.morphology import skeletonize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "L.seed_everything(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = 'danforth-raw-unet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DanforthDataset('data/danforth/images', 'data/danforth/masks')\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [0.80, 0.15, 0.05], generator=Generator().manual_seed(0))\n",
    "\n",
    "test_dataset.dataset.transform = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Display data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "num_images = 4\n",
    "for i in range(1, num_images * 2, 2):\n",
    "    random_index = torch.randint(len(dataset), size=(1,)).item()\n",
    "    image, mask = dataset[random_index].values()\n",
    "\n",
    "    figure.add_subplot(num_images, 2, i)\n",
    "    plt.title('Image')\n",
    "    plt.imshow(image.permute(1, 2, 0).squeeze())\n",
    "    figure.add_subplot(num_images, 2, i + 1)\n",
    "    plt.title('Mask')\n",
    "    plt.imshow(mask.squeeze(), cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TrainingModel(UNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(dirpath=f'checkpoints/{model_directory}',\n",
    "                                      monitor='val_loss', save_top_k=5, mode='min', save_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=5000,\n",
    "    log_every_n_steps=1,\n",
    "    precision='bf16-mixed',\n",
    "    logger=TensorBoardLogger(save_dir=f'logs/{model_directory}'),\n",
    "    profiler=PyTorchProfiler(dirpath=f'logs/{model_directory}/profiler', filename='perf_logs'),\n",
    "    callbacks=[\n",
    "        DeviceStatsMonitor(cpu_stats=True),\n",
    "        EarlyStopping(monitor='val_loss', patience=100, mode='min'),\n",
    "        checkpoint_callback,\n",
    "        RichProgressBar()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2, prefetch_factor=2)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2, prefetch_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=1, prefetch_factor=1)\n",
    "test_dataloader.dataset.transform = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "trainer.test(model, test_dataloader, ckpt_path='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Display predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(model, test_dataloader, ckpt_path='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [torch.unbind(batch, dim=0) for batch in predictions]\n",
    "samples = [item for batch in samples for item in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "for index, images in enumerate(zip(test_dataset, samples)):\n",
    "    sample, pred = images\n",
    "    image, mask = sample.values()\n",
    "\n",
    "    pred = pred.float()\n",
    "\n",
    "    figure.add_subplot(len(samples), 3, index * 3 + 1)\n",
    "    plt.title('Image')\n",
    "    plt.imshow(image.permute(1, 2, 0).squeeze())\n",
    "    figure.add_subplot(len(samples), 3, index * 3 + 2)\n",
    "    plt.title('Mask')\n",
    "    plt.imshow(mask.squeeze(), cmap='gray')\n",
    "    figure.add_subplot(len(samples), 3, index * 3 + 3)\n",
    "    plt.title('Prediction')\n",
    "    plt.imshow(pred.squeeze(), cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Calculate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = 8 / 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = (samples[1] > 0.5).squeeze().numpy().astype(np.uint8)\n",
    "skeleton = skeletonize((samples[1] > 0.5).squeeze().numpy()).astype(np.uint8)\n",
    "\n",
    "image_contours, _ = cv2.findContours((samples[1] > 0.5).squeeze().numpy().astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "skeleton_contours, _ = cv2.findContours(skeleton, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "\n",
    "figure.add_subplot(1, 2, 1)\n",
    "plt.imshow(skeleton, cmap='gray')\n",
    "plt.title('Skeleton')\n",
    "\n",
    "figure.add_subplot(1, 2, 2)\n",
    "contoured = np.zeros((400, 400), dtype=np.uint8)\n",
    "cv2.drawContours(contoured, image_contours, -1, (255, 255, 255), 1)\n",
    "plt.imshow(contoured, cmap='gray')\n",
    "plt.title('Contours')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_count = len(image_contours)\n",
    "print(f'Number of roots: {root_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_length = 0\n",
    "for contour in skeleton_contours:\n",
    "    total_length += cv2.arcLength(contour, False)\n",
    "\n",
    "total_length = total_length * scaling\n",
    "print(f'Total root length: {total_length:.5f} inches')\n",
    "print(f'Average root length: {total_length / root_count:.2f} inches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_area = torch.sum((samples[1] > 0.5).float())\n",
    "total_area = total_area * (scaling ** 2)\n",
    "print(f'Total root area: {total_area:.2f} square inches')\n",
    "print(f'Average root area: {total_area / root_count:.2f} square inches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_contour_points = np.vstack(image_contours).squeeze()\n",
    "\n",
    "diameters = []\n",
    "\n",
    "for skeleton_contour in skeleton_contours:\n",
    "    skeleton_contour_points = skeleton_contour[:, 0, :]\n",
    "\n",
    "    for point in skeleton_contour_points:\n",
    "        distances = np.linalg.norm(image_contour_points - point, axis=1)\n",
    "        closest_index = np.argmin(distances)\n",
    "\n",
    "        diameters.append(2 * distances[closest_index] * scaling)\n",
    "\n",
    "print(f'Average root diameter: {np.mean(diameters):.2f} inches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_volume = 0\n",
    "\n",
    "for diameter in diameters:\n",
    "    radius = diameter / 2\n",
    "    volume = math.pi * radius ** 2\n",
    "    total_volume += volume\n",
    "\n",
    "print(f'Total root volume: {total_volume:.2f} cubic inches')\n",
    "print(f'Average root volume: {total_volume / root_count:.2f} cubic inches')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
